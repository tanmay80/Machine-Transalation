{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UTFOlTfMAitN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a6e59d-b2e6-4423-a5c4-388278574760"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Keras-Preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG_-q2O9Qkuu",
        "outputId": "101f0f52-5f16-4258-ffc3-c01177556f9b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Keras-Preprocessing\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n",
            "Installing collected packages: Keras-Preprocessing\n",
            "Successfully installed Keras-Preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import re\n",
        "import gensim\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "Vm-nhKUa5Zia"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PGSN7fYM4pbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b236adb-75da-4427-bff9-23cd06895fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2638744/2638744 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Download the file\n",
        "\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(path_to_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUTtZaWx4ud1",
        "outputId": "db5da560-69a2-44db-8a96-4ba7cb476c2c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets/spa-eng/spa.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "  text = path.read_text(encoding='utf-8')\n",
        "\n",
        "  lines = text.splitlines()\n",
        "  pairs = [line.split('\\t') for line in lines]\n",
        "\n",
        "  context = [context for target, context in pairs]\n",
        "  target = [target for target, context in pairs]\n",
        "\n",
        "  return target, context,lines"
      ],
      "metadata": {
        "id": "_yOBImLu5HAI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_raw, context_raw,lines = load_data(path_to_file)\n"
      ],
      "metadata": {
        "id": "Pt5KjBEL5V8Z"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lowercase\n",
        "for i in range(len(target_raw)):\n",
        "  target_raw[i]=target_raw[i].lower()\n",
        "  target_raw[i] = target_raw[i].replace(\".\", \"\")\n",
        "  target_raw[i] = target_raw[i].replace(\",\", \"\")\n",
        "  target_raw[i] = re.sub(r'\\d+', '', target_raw[i])\n",
        "  target_raw[i]=target_raw[i].split()\n",
        "  target_raw[i].insert(0, '<sos>')\n",
        "  target_raw[i].insert(len(target_raw[i]), '<eos>')\n",
        "\n",
        "\n",
        "  context_raw[i]=context_raw[i].lower()\n",
        "  context_raw[i] = context_raw[i].replace(\".\", \"\")\n",
        "  context_raw[i] = context_raw[i].replace(\",\", \"\")\n",
        "  context_raw[i] = re.sub(r'\\d+', '', context_raw[i])\n",
        "  context_raw[i]=context_raw[i].split()\n",
        "  context_raw[i].insert(0, '<sos>')\n",
        "  context_raw[i].insert(len(context_raw[i]), '<eos>')"
      ],
      "metadata": {
        "id": "1tqietzp9JCS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(target_raw[54325])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57EmpL_rCjix",
        "outputId": "9700b7b7-bfb7-404e-eeef-83aff5b63620"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<sos>', 'they', 'died', 'one', 'after', 'another', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Contraction\n",
        "with open(\"/content/drive/MyDrive/contraction_expansion.txt\", 'rb') as fp:\n",
        "    contractions= pickle.load(fp)"
      ],
      "metadata": {
        "id": "Xmfh9-lE_-6D"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(target_raw[0])\n",
        "len(target_raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m7LI3aDBlc-",
        "outputId": "044164fb-9bc9-49d5-dd2b-4a9b48a9590e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<sos>', 'go', '<eos>']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118964"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Expand Contraction\n",
        "for i in range(len(target_raw)):\n",
        "  for j in range(len(target_raw[i])):\n",
        "    target=contractions.get(target_raw[i][j],None)\n",
        "    if(target!=None):\n",
        "      target_raw[i][j]=target\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "2yDqb6yHBOAl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(target_raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVd7hCT07kbz",
        "outputId": "d2f9d8bf-e628-4426-c68c-26730c8f89ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118964"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lines[1])\n",
        "print(context_raw[8688])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNKuePpw5Xu-",
        "outputId": "93086c2f-fbaf-4218-8579-781642e8d779"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go.\tVete.\n",
            "['<sos>', 'mary', 'está', 'radiante', '<eos>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Fit the tokenizer on your text data\n",
        "tokenizer.fit_on_texts(target_raw)\n",
        "\n",
        "# Convert the text to a sequence of integers\n",
        "#context_seq = tokenizer.texts_to_sequences(context_raw)\n",
        "target_seq = tokenizer.texts_to_sequences(target_raw)\n",
        "\n"
      ],
      "metadata": {
        "id": "97bYcUFTOSeo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_seq[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnq1sUV8Of3_",
        "outputId": "26545972-8f28-4f47-adfc-48db483b3c1b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 42, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sent(text):\n",
        "  '''\n",
        "  Take list on texts as input and \n",
        "  returns its tokenizer and enocoded text\n",
        "  '''\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(text)\n",
        "\n",
        "  return tokenizer, tokenizer.texts_to_sequences(text)\n"
      ],
      "metadata": {
        "id": "VarhoKtfO3nH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize english and marathi sentences\n",
        "eng_tokenizer, eng_encoded= tokenize_sent(text= target_raw)\n",
        "spanish_tokenizer, spanish_encoded= tokenize_sent(text= context_raw)"
      ],
      "metadata": {
        "id": "Fc9-bA9nO5bB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# English Word --> index dictionary\n",
        "eng_index_word = eng_tokenizer.index_word\n",
        "\n",
        "# English Index --> word dictionary\n",
        "eng_word_index= eng_tokenizer.word_index\n",
        "\n",
        "# size of English vocabulary for encoder input\n",
        "# For zero padding we have to add +1 in size\n",
        "ENG_VOCAB_SIZE = len(eng_tokenizer.word_counts)+1\n",
        "\n",
        "# Spanish Word --> index dict\n",
        "spanish_word_index= spanish_tokenizer.word_index\n",
        "\n",
        "# Spanish Index --> word dict\n",
        "spanish_index_word = spanish_tokenizer.index_word\n",
        "# Spanish vocab size for decoder output\n",
        "SPA_VOCAB_SIZE=len(spanish_tokenizer.word_counts)+1\n",
        "\n",
        "# Getting max length of English and Spanish sentences\n",
        "max_eng_len = 0\n",
        "for i in range(len(eng_encoded)):\n",
        "  if len(eng_encoded[i]) > max_eng_len:\n",
        "    max_eng_len= len(eng_encoded[i])\n",
        "\n",
        "max_spa_len = 0\n",
        "for i in range(len(spanish_encoded)):\n",
        "  if len(eng_encoded[i]) > max_spa_len:\n",
        "    max_spa_len= len(spanish_encoded[i])\n",
        "\n",
        "    \n",
        "# Padding both\n",
        "eng_padded = pad_sequences(eng_encoded, maxlen=max_eng_len, padding='post')\n",
        "spa_padded = pad_sequences(spanish_encoded, maxlen=max_spa_len, padding='post')\n",
        "\n",
        "# Convert to array\n",
        "eng_padded= np.array(eng_padded)\n",
        "spa_padded= np.array(spa_padded)\n",
        "\n",
        "# Split data into train and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(spa_padded, eng_padded, test_size=0.1, random_state=0)\n"
      ],
      "metadata": {
        "id": "85eYtBhsPWcn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "5f8d26b7-d01b-46e8-e207-79fea32a7380"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-021e17be7738>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# English Word --> index dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0meng_index_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meng_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# English Index --> word dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0meng_word_index\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0meng_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'eng_tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOjIs0TwQRH5",
        "outputId": "f2371dd5-5be5-469b-c5e6-1af1ca0d5572"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,   23, 2480, ...,    0,    0,    0],\n",
              "       [   1,   24,   42, ...,    0,    0,    0],\n",
              "       [   1,   13, 1407, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   1, 4683,    9, ...,    0,    0,    0],\n",
              "       [   1,  881,  613, ...,    0,    0,    0],\n",
              "       [   1,   15,    6, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path=\"/content/drive/MyDrive/GoogleNews-vectors-negative300.bin\""
      ],
      "metadata": {
        "id": "lkgCdGFhRBom"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec = KeyedVectors.load_word2vec_format(path, binary=True)"
      ],
      "metadata": {
        "id": "zxs8Ots0SkXG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 300\n",
        "VOCABULARY_SIZE = len(eng_tokenizer.word_index) + 1# create an empty embedding matix\n",
        "english_embedding_weights = np.zeros((VOCABULARY_SIZE, EMBEDDING_SIZE))# create a word to index dictionary mapping\n",
        "word2id = eng_tokenizer.word_index# copy vectors from word2vec model to the words present in corpus\n",
        "for word, index in word2id.items():\n",
        "  try:\n",
        "    english_embedding_weights[index, :] = word2vec[word]\n",
        "  except KeyError:\n",
        "    pass\n",
        "# check embedding dimension\n",
        "print(\"Embeddings shape: {}\".format(english_embedding_weights.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neZLnth1SmdW",
        "outputId": "6d39856e-7c7e-48b7-ef8e-f3257469a641"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (16546, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCABULARY_SIZE_ENGLISH = len(eng_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "c2Ii8w8nG5E1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove = gensim.models.KeyedVectors.load_word2vec_format('/content/drive/MyDrive/SBW-vectors-300-min5.txt')"
      ],
      "metadata": {
        "id": "wl5Ktv2V4NaU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 300\n",
        "VOCABULARY_SIZE = len(spanish_tokenizer.word_index) + 1# create an empty embedding matix\n",
        "spanish_embedding_weights = np.zeros((VOCABULARY_SIZE, EMBEDDING_SIZE))# create a word to index dictionary mapping\n",
        "word2id = spanish_tokenizer.word_index# copy vectors from word2vec model to the words present in corpus\n",
        "for word, index in word2id.items():\n",
        "  try:\n",
        "    spanish_embedding_weights[index, :] = glove[word]\n",
        "  except KeyError:\n",
        "    pass\n",
        "# check embedding dimension\n",
        "print(\"Embeddings shape: {}\".format(spanish_embedding_weights.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK6P1f2gV3l3",
        "outputId": "49053312-e300-4f7f-8ad7-c6e418b71ef9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings shape: (31034, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VOCABULARY_SIZE_SPANISH = len(spanish_tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "XlajZz0fImzy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Embedding, Concatenate\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "# Encoder input\n",
        "encoder_inputs = Input(shape=(max_spa_len,)) \n",
        "\n",
        "print(encoder_inputs.shape)\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(VOCABULARY_SIZE_SPANISH, EMBEDDING_SIZE, weights=[spanish_embedding_weights])(encoder_inputs)\n",
        "\n",
        "print(enc_emb.shape)\n",
        "\n",
        "# Bidirectional lstm layer\n",
        "enc_lstm1 = Bidirectional(LSTM(256,return_sequences=True,return_state=True))\n",
        "\n",
        "\n",
        "encoder_outputs1, forw_state_h, forw_state_c, back_state_h, back_state_c = enc_lstm1(enc_emb)\n",
        "\n",
        "\n",
        "print(forw_state_h)\n",
        "print(forw_state_c)\n",
        "print(encoder_outputs1)\n",
        "\n",
        "# Concatenate both h and c \n",
        "final_enc_h = Concatenate()([forw_state_h,back_state_h])\n",
        "print(np.shape(final_enc_h))\n",
        "final_enc_c = Concatenate()([forw_state_c,back_state_c])\n",
        "\n",
        "# get Context vector\n",
        "encoder_states =[final_enc_h, final_enc_c]\n",
        "\n",
        "print(encoder_states)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDozJGtq7JoY",
        "outputId": "60f701c4-b657-4807-8dd5-2812818b275f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 51)\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name=None), name='bidirectional/forward_lstm/PartitionedCall:2', description=\"created by layer 'bidirectional'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 256), dtype=tf.float32, name=None), name='bidirectional/forward_lstm/PartitionedCall:3', description=\"created by layer 'bidirectional'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 51, 512), dtype=tf.float32, name=None), name='bidirectional/concat:0', description=\"created by layer 'bidirectional'\")\n",
            "(None, 512)\n",
            "[<KerasTensor: shape=(None, 512) dtype=float32 (created by layer 'concatenate')>, <KerasTensor: shape=(None, 512) dtype=float32 (created by layer 'concatenate_1')>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(enc_emb.shape)\n",
        "print(enc_lstm1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "VbAgzXoRJQ_K",
        "outputId": "4cc822ca-dfde-488d-c52f-6a4b6831fe20"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 51, 300)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-0aed477607d5>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_lstm1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Bidirectional' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_spa_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENnTuGrVGqL5",
        "outputId": "d9cfa7d7-06a0-433b-b07a-8d28b772caf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "os.chdir(\"/content/drive/MyDrive/NLP\")\n",
        "from BahdanauAttention import AttentionLayer\n",
        "\n",
        "#call attention using:\n",
        "from tensorflow.keras.layers import AdditiveAttention\n",
        "\n",
        " \n"
      ],
      "metadata": {
        "id": "9TBBlORISDPW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  decoder input\n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "\n",
        "# decoder embedding with same number as encoder embedding\n",
        "dec_emb_layer = Embedding(VOCABULARY_SIZE_ENGLISH, 300,weights=[english_embedding_weights]) \n",
        "dec_emb = dec_emb_layer(decoder_inputs)   # apply this way because we need embedding layer for prediction \n",
        "\n",
        "# In encoder we used Bidirectional so it's having two LSTM's so we have to take double units(256*2=512) for single decoder lstm\n",
        "# LSTM using encoder's final states as initial state\n",
        "decoder_lstm = LSTM(512, return_sequences=True, return_state=True) \n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "\n",
        "print(encoder_outputs1.shape)\n",
        "print(decoder_outputs.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcyfKLTKLMwm",
        "outputId": "1ebe36c2-19af-4c55-8c0c-c1f026287ea7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 51, 512)\n",
            "(None, None, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder_inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etjFacyqLmGO",
        "outputId": "cb56a661-7fa1-42ca-a710-0d6ca1a28f41"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Attention Layer\n",
        "attention_layer = AttentionLayer()\n",
        "\n",
        "#Modify your code and provide decoder_outputs first and encoder_outputs next as parameters.\n",
        "attention_result = AdditiveAttention(use_scale=True)([decoder_outputs, encoder_outputs1])\n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attention_result])\n",
        "\n",
        "# Dense layer with softmax\n",
        "decoder_dense = Dense(VOCABULARY_SIZE_ENGLISH, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) "
      ],
      "metadata": {
        "id": "bdoDoav1cwdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTynThAwX5a6",
        "outputId": "a9818701-ee2c-4023-88ba-34fd095287d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 51)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 51, 300)      9310200     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  [(None, 51, 512),    1140736     ['embedding[0][0]']              \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 300)    4963800     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 512)          0           ['bidirectional[0][1]',          \n",
            "                                                                  'bidirectional[0][3]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 512)          0           ['bidirectional[0][2]',          \n",
            "                                                                  'bidirectional[0][4]']          \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 512),  1665024     ['embedding_1[0][0]',            \n",
            "                                 (None, 512),                     'concatenate[0][0]',            \n",
            "                                 (None, 512)]                     'concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " additive_attention (AdditiveAt  (None, None, 512)   512         ['lstm_1[0][0]',                 \n",
            " tention)                                                         'bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, None, 1024)   0           ['lstm_1[0][0]',                 \n",
            "                                                                  'additive_attention[0][0]']     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 16546)  16959650    ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 34,039,922\n",
            "Trainable params: 34,039,922\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "wBaS5fbQev_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "encoder_input_data = X_train\n",
        "# To make same as target data skip last number which is just padding\n",
        "decoder_input_data = y_train[:,:-1]\n",
        "# Decoder target data has to be one step ahead so we are taking from 1 as told in keras docs\n",
        "decoder_target_data =  y_train[:,1:]\n",
        "\n",
        "# Testing\n",
        "encoder_input_test = X_test\n",
        "decoder_input_test = y_test[:,:-1]\n",
        "decoder_target_test=  y_test[:,1:]"
      ],
      "metadata": {
        "id": "_tElITblX7qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS= 5"
      ],
      "metadata": {
        "id": "WMYRmJN8YL_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([encoder_input_data, decoder_input_data],decoder_target_data, \n",
        "                    epochs=EPOCHS, \n",
        "                    batch_size=128,\n",
        "                    validation_data = ([encoder_input_test, decoder_input_test],decoder_target_test),\n",
        "                    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx466UINYVLm",
        "outputId": "a59b4ace-fe73-4eb7-efce-c0ec46629069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "837/837 [==============================] - 312s 367ms/step - loss: 0.8363 - accuracy: 0.8810 - val_loss: 0.6308 - val_accuracy: 0.8957\n",
            "Epoch 2/5\n",
            "837/837 [==============================] - 317s 378ms/step - loss: 0.5549 - accuracy: 0.9054 - val_loss: 0.5006 - val_accuracy: 0.9132\n",
            "Epoch 3/5\n",
            "837/837 [==============================] - 318s 380ms/step - loss: 0.4386 - accuracy: 0.9205 - val_loss: 0.4281 - val_accuracy: 0.9234\n",
            "Epoch 4/5\n",
            "837/837 [==============================] - 325s 389ms/step - loss: 0.3533 - accuracy: 0.9317 - val_loss: 0.3705 - val_accuracy: 0.9320\n",
            "Epoch 5/5\n",
            "837/837 [==============================] - 326s 390ms/step - loss: 0.2868 - accuracy: 0.9413 - val_loss: 0.3345 - val_accuracy: 0.9376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"/content/drive/MyDrive/NLP/achaModel.h5\")"
      ],
      "metadata": {
        "id": "O3GG__UZYa4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"/content/drive/MyDrive/NLP/achaModel.h5\")"
      ],
      "metadata": {
        "id": "fQDLAGvFkwC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_model = Model(encoder_inputs, outputs = [encoder_outputs1, final_enc_h, final_enc_c])\n",
        "\n",
        "decoder_state_h = Input(shape=(512,))\n",
        "decoder_state_c = Input(shape=(512,))\n",
        "decoder_hidden_state_input = Input(shape=(max_spa_len,512))\n",
        "\n",
        "dec_states = [decoder_state_h, decoder_state_c]\n",
        "\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=dec_states)\n",
        "\n",
        "print(decoder_outputs2.shape)\n",
        "print(decoder_hidden_state_input.shape)\n",
        "\n",
        "# Attention inference\n",
        "attention_result_inf= AdditiveAttention(use_scale=True)([decoder_hidden_state_input, decoder_outputs2])\n",
        "\n",
        "decoder_concat_input_inf = Concatenate(axis=-1, name='concat_layer')([decoder_outputs2, attention_result_inf])\n",
        "\n",
        "dec_states2= [state_h2, state_c2]\n",
        "\n",
        "decoder_outputs2 = decoder_dense(decoder_concat_input_inf)\n",
        "\n",
        "decoder_model= Model(\n",
        "                    [decoder_inputs] + [decoder_hidden_state_input, decoder_state_h, decoder_state_c],\n",
        "                     [decoder_outputs2]+ dec_states2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6XbOlvZnzSM",
        "outputId": "245e3ead-4d60-4390-dc75-eb62ee4ac962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, None, 512)\n",
            "(None, 51, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "decoder_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyVfVPW35rHm",
        "outputId": "7523c873-4fb9-4677-b2ed-cfeb39b589bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_21\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_13 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, None, 300)    4963800     ['input_13[0][0]']               \n",
            "                                                                                                  \n",
            " input_41 (InputLayer)          [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_42 (InputLayer)          [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " input_43 (InputLayer)          [(None, 51, 512)]    0           []                               \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 512),  1665024     ['embedding_3[10][0]',           \n",
            "                                 (None, 512),                     'input_41[0][0]',               \n",
            "                                 (None, 512)]                     'input_42[0][0]']               \n",
            "                                                                                                  \n",
            " additive_attention_10 (Additiv  (None, 51, 512)     512         ['input_43[0][0]',               \n",
            " eAttention)                                                      'lstm_3[10][0]']                \n",
            "                                                                                                  \n",
            " concat_layer (Concatenate)     (None, 51, 1024)     0           ['input_43[0][0]',               \n",
            "                                                                  'additive_attention_10[0][0]']  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                multiple             16959650    ['concat_layer[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,588,986\n",
            "Trainable params: 23,588,986\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predicted_sentence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    enc_output, enc_h, enc_c = encoder_model.predict(input_seq)\n",
        "  \n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    \n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = eng_word_index['<sos>']\n",
        "    \n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    \n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [enc_output, enc_h, enc_c ])\n",
        "        print(output_tokens)\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        print(sampled_token_index)\n",
        "        if sampled_token_index == 0:\n",
        "          break\n",
        "        else:\n",
        "            # convert max index number to marathi word\n",
        "            sampled_char = eng_index_word[sampled_token_index]\n",
        "\n",
        "        if (sampled_char!='<eos>'):\n",
        "            # aapend it ti decoded sent\n",
        "            decoded_sentence += ' '+sampled_char\n",
        "        \n",
        "        # Exit condition: either hit max length or find stop token.\n",
        "        if (sampled_char == '<eos>' or len(decoded_sentence.split()) >= 10):\n",
        "            stop_condition = True\n",
        "        \n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        \n",
        "        # Update states\n",
        "        enc_h, enc_c = h, c\n",
        "    \n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "aenoqcgVw0wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_spanish_sentence(input_sequence):\n",
        "    sentence =''\n",
        "    for i in input_sequence:\n",
        "      if i!=0 :\n",
        "        sentence =sentence +eng_index_word[i]+' '\n",
        "    return sentence \n",
        "\n",
        "def get_english_sentence(input_sequence):\n",
        "    sentence =''\n",
        "    for i in input_sequence:\n",
        "      if i!=0:\n",
        "        sentence =sentence +spanish_index_word[i]+' '\n",
        "    return sentence     "
      ],
      "metadata": {
        "id": "i8uMkgSky4ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_word_index['<eos>']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK7GygfZ3jlX",
        "outputId": "20769a05-40d7-4718-e0ae-087bd90b5e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=1000\n",
        "print(\"Spanish Sentence:\",get_english_sentence(X_test[i]))\n",
        "print(\"Actual English Sentence:\",get_spanish_sentence(y_test[i])[4:-4])\n",
        "# Before passing input it has to be reshape as following\n",
        "print(\"Predicted Spanish Translation:\",get_predicted_sentence(X_test[i].reshape(1,51))[:-4])\n",
        "print(\"----------------------------------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "wbjvcsY3y-yW",
        "outputId": "332bbbe9-bfb5-48e1-dd0f-e5ca38c7a9b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-901d312e90f1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Spanish Sentence:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_english_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Actual English Sentence:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_spanish_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Before passing input it has to be reshape as following\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted Spanish Translation:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_predicted_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m51\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_english_sentence' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spanish_index_word[14291]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3q737V97zCyC",
        "outputId": "e157401b-a34b-4842-ca4e-130a39ad54aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ovni?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6AKBn0pt17kK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}